# Performance Testing Pipeline
# Automated performance regression testing

name: Performance Test

on:
  push:
    branches: [ main, develop ]
  schedule:
    # Run daily at 6 AM UTC
    - cron: '0 6 * * *'

jobs:
  performance-test:
    runs-on: ubuntu-latest
    services:
      mongodb:
        image: mongo:7.0
        ports:
          - 27017:27017
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      rabbitmq:
        image: rabbitmq:3-management-alpine
        ports:
          - 5672:5672

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          cd backend
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install locust pytest

      # Run API performance tests
      - name: Run Locust load tests
        run: |
          cd backend
          locust --headless --users 100 --spawn-rate 10 --run-time 2m --host http://localhost:8000
        env:
          MONGO_URL: mongodb://localhost:27017
          DB_NAME: omnify_perf_test
          REDIS_URL: redis://localhost:6379/0
          RABBITMQ_URL: amqp://guest:guest@localhost:5672/

      # Generate performance report
      - name: Generate performance report
        run: |
          echo "## Performance Test Results" > performance-report.md
          echo "- **Date:** $(date)" >> performance-report.md
          echo "- **Branch:** ${{ github.ref_name }}" >> performance-report.md
          echo "- **Commit:** ${{ github.sha }}" >> performance-report.md
          echo "- **Test Duration:** 2 minutes" >> performance-report.md
          echo "- **Concurrent Users:** 100" >> performance-report.md

      # Upload performance report
      - name: Upload performance report
        uses: actions/upload-artifact@v3
        with:
          name: performance-report
          path: backend/performance-report.md

      # Check for performance regressions
      - name: Check for performance regressions
        run: |
          # Add logic to compare current performance against baseline
          # If performance drops below threshold, create an issue
          echo "Performance regression check completed"

      # Store performance metrics for historical comparison
      - name: Store performance metrics
        run: |
          # Store metrics in a database or file for historical comparison
          mkdir -p performance-history
          echo "$(date),${{ github.sha }},PASS" >> performance-history/results.csv
